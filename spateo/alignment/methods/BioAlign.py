import random

import numpy as np
import ot
import torch
from anndata import AnnData

try:
    from typing import Any, Dict, List, Literal, Optional, Tuple, Union
except ImportError:
    from typing_extensions import Literal

from typing import List, Optional, Tuple, Union

from spateo.logging import logger_manager as lm

from .utils import (
    _data,
    _dot,
    _identity,
    _linalg,
    _mul,
    _pi,
    _pinv,
    _power,
    _prod,
    _psi,
    _unique,
    _unsqueeze,
    align_preprocess,
    cal_dist,
    calc_exp_dissimilarity,
    coarse_rigid_alignment,
    empty_cache,
    shape_align_preprocess,
)


def con_K(
    X: Union[np.ndarray, torch.Tensor],
    Y: Union[np.ndarray, torch.Tensor],
    beta: Union[int, float] = 0.01,
    use_chunk: bool = False,
) -> Union[np.ndarray, torch.Tensor]:
    """con_K constructs the Squared Exponential (SE) kernel, where K(i,j)=k(X_i,Y_j)=exp(-beta*||X_i-Y_j||^2).

    Args:
        X: The first vector X\in\mathbb{R}^{N\times d}
        Y: The second vector X\in\mathbb{R}^{M\times d}
        beta: The length-scale of the SE kernel.
        use_chunk (bool, optional): Whether to use chunk to reduce the GPU memory usage. Note that if set to ``True'' it will slow down the calculation. Defaults to False.

    Returns:
        K: The kernel K\in\mathbb{R}^{N\times M}
    """

    assert X.shape[1] == Y.shape[1], "X and Y do not have the same number of features."
    nx = ot.backend.get_backend(X, Y)

    K = cal_dist(X, Y)
    K = nx.exp(-beta * K)
    return K


############
# BioAlign #
############
def get_P(
    XnAHat: Union[np.ndarray, torch.Tensor],
    XnB: Union[np.ndarray, torch.Tensor],
    sigma2: Union[int, float, np.ndarray, torch.Tensor],
    beta2: Union[int, float, np.ndarray, torch.Tensor],
    alpha: Union[np.ndarray, torch.Tensor],
    gamma: Union[float, np.ndarray, torch.Tensor],
    Sigma: Union[np.ndarray, torch.Tensor],
    GeneDistMat: Union[np.ndarray, torch.Tensor],
    SpatialDistMat: Union[np.ndarray, torch.Tensor],
    samples_s: Optional[List[float]] = None,
    outlier_variance: float = None,
) -> Union[np.ndarray, torch.Tensor]:
    """Calculating the generating probability matrix P.

    Args:
        XAHat: Current spatial coordinate of sample A. Shape: N x D.
        XnB : spatial coordinate of sample B (reference sample). Shape: M x D.
        sigma2: The spatial coordinate noise.
        beta2: The gene expression noise.
        alpha: A vector that encoding each probability generated by the spots of sample A. Shape: N x 1.
        gamma: Inlier proportion of sample A.
        Sigma: The posterior covariance matrix of Gaussian process. Shape: N x N or N x 1.
        GeneDistMat: The gene expression distance matrix between sample A and sample B. Shape: N x M.
        SpatialDistMat: The spatial coordinate distance matrix between sample A and sample B. Shape: N x M.
        samples_s: The space size of each sample. Area size for 2D samples and volume size for 3D samples.
        outlier_g: The outlier distribution output space volume attributed to gene expression.
    Returns:
        P: Generating probability matrix P. Shape: N x M.
    """

    assert XnAHat.shape[1] == XnB.shape[1], "XnAHat and XnB do not have the same number of features."
    assert XnAHat.shape[0] == alpha.shape[0], "XnAHat and alpha do not have the same length."
    assert XnAHat.shape[0] == Sigma.shape[0], "XnAHat and Sigma do not have the same length."

    nx = ot.backend.get_backend(XnAHat, XnB)
    NA, NB, D = XnAHat.shape[0], XnB.shape[0], XnAHat.shape[1]
    if samples_s is None:
        samples_s = nx.maximum(
            _prod(nx)(nx.max(XnAHat, axis=0) - nx.min(XnAHat, axis=0)),
            _prod(nx)(nx.max(XnB, axis=0) - nx.min(XnB, axis=0)),
        )
    outlier_s = samples_s * NA
    if outlier_variance is None:
        exp_SpatialMat = nx.exp(-SpatialDistMat / (2 * sigma2))
    else:
        exp_SpatialMat = nx.exp(-SpatialDistMat / (2 * sigma2 / outlier_variance))
    spatial_term1 = nx.einsum(
        "ij,i->ij",
        exp_SpatialMat,
        (_mul(nx)(alpha, nx.exp(-Sigma / sigma2))),
    )
    spatial_outlier = _power(nx)((2 * _pi(nx) * sigma2), _data(nx, D / 2, XnAHat)) * (1 - gamma) / (gamma * outlier_s)
    spatial_term2 = spatial_outlier + nx.einsum("ij->j", spatial_term1)
    spatial_P = spatial_term1 / _unsqueeze(nx)(spatial_term2, 0)
    spatial_inlier = 1 - spatial_outlier / (spatial_outlier + nx.einsum("ij->j", exp_SpatialMat))
    term1 = nx.einsum(
        "ij,i->ij",
        _mul(nx)(nx.exp(-SpatialDistMat / (2 * sigma2)), nx.exp(-GeneDistMat / (2 * beta2))),
        (_mul(nx)(alpha, nx.exp(-Sigma / sigma2))),
    )
    P = term1 / (_unsqueeze(nx)(nx.einsum("ij->j", term1), 0) + 1e-8)
    P = nx.einsum("j,ij->ij", spatial_inlier, P)
    return P, spatial_P


def BA_align(
    sampleA: AnnData,
    sampleB: AnnData,
    genes: Optional[Union[List, torch.Tensor]] = None,
    spatial_key: str = "spatial",
    key_added: str = "align_spatial",
    iter_key_added: Optional[str] = "iter_spatial",
    vecfld_key_added: Optional[str] = "VecFld_morpho",
    layer: str = "X",
    mode: Literal["S", "N", "SN", "NS"] = "SN",
    dissimilarity: str = "kl",
    keep_size: bool = False,
    max_iter: int = 100,
    lambdaVF: Union[int, float] = 1e2,
    beta: Union[int, float] = 0.01,
    beta2: Optional[Union[int, float]] = None,
    outlier_g: Optional[Union[int, float]] = None,
    K: Union[int, float] = 15,
    normalize_c: bool = True,
    normalize_g: bool = True,
    select_high_exp_genes: Union[bool, float, int] = False,
    dtype: str = "float64",
    device: str = "cpu",
    inplace: bool = True,
    verbose: bool = True,
    added_similarity: Optional[Union[torch.Tensor, np.ndarray]] = None,
    added_scale: Optional[float] = 0.5,
    partial_alignment: bool = False,
    proliferation_prior: Optional[Union[torch.Tensor, np.ndarray]] = None,
    proliferation_prior_weight: float = 1.0,
    nn_init: bool = False,
) -> Tuple[Optional[Tuple[AnnData, AnnData]], np.ndarray, np.ndarray]:
    """_summary_

    Args:
        sampleA: Sample A that acts as reference.
        sampleB: Sample B that performs alignment.
        genes: Genes used for calculation. If None, use all common genes for calculation.
        spatial_key: The key in ``.obsm`` that corresponds to the raw spatial coordinate.
        key_added: ``.obsm`` key under which to add the aligned spatial coordinate.
        iter_key_added: ``.uns`` key under which to add the result of each iteration of the iterative process. If ``iter_key_added`` is None, the results are not saved.
        vecfld_key_added: The key that will be used for the vector field key in ``.uns``. If ``vecfld_key_added`` is None, the results are not saved.
        layer: If ``'X'``, uses ``.X`` to calculate dissimilarity between spots, otherwise uses the representation given by ``.layers[layer]``.
        mode: The method of alignment. Available ``mode`` are: ``'S'``, ``'N'`` and ``'SN'``.
        dissimilarity: Expression dissimilarity measure: ``'kl'`` or ``'euclidean'``.
        small_variance: When approximating the assignment matrix, if True, we use small sigma2 (0.001) rather than the infered sigma2
        max_iter: Max number of iterations for morpho alignment.
        lambdaVF : Hyperparameter that controls the non-rigid distortion degree. Smaller means more flexibility.
        beta: The length-scale of the SE kernel. Higher means more flexibility.
        beta2:
        K: The number of sparse inducing points used for Nystr Ìˆom approximation. Smaller means faster but less accurate.
        normalize_c: Whether to normalize spatial coordinates.
        normalize_g: Whether to normalize gene expression. If ``dissimilarity`` == ``'kl'``, ``normalize_g`` must be False.
        select_high_exp_genes: Whether to select genes with high differences in gene expression.
        samples_s: The space size of each sample. Area size for 2D samples and volume size for 3D samples.
        dtype: The floating-point number type. Only ``float32`` and ``float64``.
        device: Equipment used to run the program. You can also set the specified GPU for running. ``E.g.: '0'``.
        inplace: Whether to copy adata or modify it inplace.
        verbose: If ``True``, print progress updates.
        added_similarity: The similarity matrix of the added other modality with shape n x m.
        added_scale: The scale of the added similarity matrix. Interval from 0 to 1.
        partial_alignment: Whether to use partial alignment. Note that setting to True does not affect the alignment of two very similar samples. If you are aligning two samples with very different morphology, e.g., across time, you can set to False.
    """

    # Check the method of alignment.
    assert mode in [
        "S",
        "N",
        "SN",
    ], "``mode`` value is wrong. Available ``mode`` are: ``'S'``, ``'N'`` and ``'SN'``."
    if mode == "NS":
        mode = "SN"
    if proliferation_prior is not None:
        assert (
            proliferation_prior.shape[0] == sampleB.shape[0]
        ), "the length of proliferation_prior should match the length of sample B"

    # Preprocessing
    normalize_g = False if dissimilarity == "kl" else normalize_g
    sampleA, sampleB = (sampleA, sampleB) if inplace else (sampleA.copy(), sampleB.copy())
    (nx, type_as, new_samples, exp_matrices, spatial_coords, normalize_scale, normalize_mean_list,) = align_preprocess(
        samples=[sampleA, sampleB],
        layer=layer,
        genes=genes,
        spatial_key=spatial_key,
        normalize_c=normalize_c,
        normalize_g=normalize_g,
        select_high_exp_genes=select_high_exp_genes,
        dtype=dtype,
        device=device,
        verbose=verbose,
    )
    if added_similarity is not None:
        added_similarity = _data(nx, added_similarity, type_as)
    coordsA, coordsB = spatial_coords[1], spatial_coords[0]
    X_A, X_B = exp_matrices[1], exp_matrices[0]
    NA, NB, D, G = coordsA.shape[0], coordsB.shape[0], coordsA.shape[1], X_A.shape[1]
    GeneDistMat = calc_exp_dissimilarity(X_A=X_A, X_B=X_B, dissimilarity=dissimilarity, chunk_num=5)
    GeneDistMatMinus = GeneDistMat - nx.min(GeneDistMat, axis=1, keepdims=True)
    if added_similarity is not None:
        GeneDistMat = GeneDistMat + added_scale * added_similarity
        del added_similarity
    area = _prod(nx)(nx.max(coordsA, axis=0) - nx.min(coordsA, axis=0))

    # Random select control points
    Unique_coordsA = _unique(nx, coordsA, 0)
    idx = random.sample(range(Unique_coordsA.shape[0]), min(K, Unique_coordsA.shape[0]))
    ctrl_pts = Unique_coordsA[idx, :]

    # construct the kernel
    GammaSparse = con_K(ctrl_pts, ctrl_pts, beta)
    U = con_K(coordsA, ctrl_pts, beta)

    # initialize parameters
    if proliferation_prior is None:
        kappa = nx.ones((NA), type_as=type_as)
    else:
        kappa = _data(nx, proliferation_prior, type_as)
    kappa = proliferation_prior_weight * kappa
    alpha = nx.ones((NA), type_as=type_as)
    VnA = nx.zeros(coordsA.shape, type_as=type_as)
    Coff = nx.zeros(ctrl_pts.shape, type_as=type_as)

    gamma, gamma_a, gamma_b = (
        _data(nx, 0.5, type_as),
        _data(nx, 1.0, type_as),
        _data(nx, 1.0, type_as),
    )
    minP, sigma2_terc, erc = (
        _data(nx, 1e-5, type_as),
        _data(nx, 1, type_as),
        _data(nx, 1e-4, type_as),
    )
    SigmaDiag = nx.zeros((NA), type_as=type_as)
    XAHat, RnA = coordsA, coordsA

    if nn_init:
        # perform coarse rigid alignment
        XAHat = _data(nx, coarse_rigid_alignment(XAHat, coordsB, GeneDistMat, nx), type_as)
    # coarse_alignment = _data(nx,coarse_rigid_alignment(XAHat, coordsB, GeneDistMat, nx),type_as)
    coarse_alignment = XAHat
    SpatialDistMat = cal_dist(XAHat, coordsB)
    sigma2 = 100 * nx.sum(SpatialDistMat) / (D * NA * NB)  # 2 for 3D
    s = _data(nx, 1, type_as)
    # minGeneDistMat = nx.maximum(nx.min(GeneDistMat,1),_data(nx,0.05,type_as))
    minGeneDistMat = nx.min(GeneDistMat, 1)
    # Automatically determine the value of beta2
    if beta2 is None:
        if partial_alignment:
            # beta2_end = minGeneDistMat[nx.argsort(minGeneDistMat)[int(GeneDistMat.shape[0]*0.1)]] / 5
            # beta2 = minGeneDistMat[nx.argsort(minGeneDistMat)[int(GeneDistMat.shape[0]*0.05)]] / 10
            # beta2_end = nx.max(minGeneDistMat)
            beta2 = minGeneDistMat[nx.argsort(minGeneDistMat)[int(GeneDistMat.shape[0] * 0.05)]] * 2
            beta2_end = nx.maximum(
                minGeneDistMat[nx.argsort(minGeneDistMat)[int(GeneDistMat.shape[0] * 0.1)]] / 40,
                _data(nx, 0.01, type_as),
            )  # DLPFC partial
        else:
            # beta2_end = minGeneDistMat[nx.argsort(minGeneDistMat)[int(max(GeneDistMat.shape[0]*0.1,min(30,GeneDistMat.shape[0])-1))]]  # C elegans
            beta2_end = nx.max(minGeneDistMat)
            beta2 = minGeneDistMat[nx.argsort(minGeneDistMat)[int(GeneDistMat.shape[0] * 0.05)]] / 5
    # The value of beta2 becomes progressively larger
    beta2_decrease = _power(nx)(beta2_end / beta2, 1 / (50))
    if verbose:
        print("{:0>2f} --> {:0>2f}".format(beta2, beta2_end))
    # If partial alignment, use smaller spatial variance to reduce tails
    outlier_variance = 1
    max_outlier_variance = 5  # 20
    outlier_variance_decrease = _power(nx)(_data(nx, max_outlier_variance, type_as), 1 / (max_iter / 2))

    iteration = (
        lm.progress_logger(range(max_iter), progress_name="Start morpho alignment") if verbose else range(max_iter)
    )
    if iter_key_added is not None:
        sampleB.uns[iter_key_added] = dict()
        sampleB.uns[iter_key_added][key_added] = {}
        sampleB.uns[iter_key_added]["sigma2"] = {}
        sampleB.uns[iter_key_added]["beta2"] = {}
        sampleB.uns[iter_key_added]["scale"] = {}

    for iter in iteration:
        if iter_key_added is not None:
            iter_XAHat = XAHat * normalize_scale + normalize_mean_list[0] if normalize_c else XAHat
            sampleB.uns[iter_key_added][key_added][iter] = nx.to_numpy(iter_XAHat)
            sampleB.uns[iter_key_added]["sigma2"][iter] = nx.to_numpy(sigma2)
            sampleB.uns[iter_key_added]["beta2"][iter] = nx.to_numpy(beta2)
            sampleB.uns[iter_key_added]["scale"][iter] = nx.to_numpy(s)
        P, spatial_P = get_P(
            XnAHat=XAHat,
            XnB=coordsB,
            sigma2=sigma2,
            beta2=beta2,
            alpha=alpha,
            gamma=gamma,
            Sigma=SigmaDiag,
            GeneDistMat=GeneDistMat,
            SpatialDistMat=SpatialDistMat,
            outlier_variance=outlier_variance,
        )
        # print(alpha)
        if iter > 5:
            if beta2_decrease < 1:
                beta2 = nx.maximum(beta2 * beta2_decrease, beta2_end)
            else:
                beta2 = nx.minimum(beta2 * beta2_decrease, beta2_end)
            if partial_alignment and iter > max_iter / 2:
                outlier_variance = nx.minimum(outlier_variance * outlier_variance_decrease, max_outlier_variance)
        K_NA = nx.einsum("ij->i", P)
        K_NB = nx.einsum("ij->j", P)
        K_NA_spatial = nx.einsum("ij->i", spatial_P)
        K_NB_spatial = nx.einsum("ij->j", spatial_P)

        # Update gamma
        Sp = nx.einsum("ij->", P)
        Sp_spatial = nx.einsum("ij->", spatial_P)
        gamma = nx.exp(_psi(nx)(gamma_a + Sp_spatial) - _psi(nx)(gamma_a + gamma_b + NB))
        gamma = _data(nx, 0.99, type_as) if gamma > 0.99 else gamma
        gamma = _data(nx, 0.01, type_as) if gamma < 0.01 else gamma

        # Update alpha
        if partial_alignment or (proliferation_prior is not None):
            # print("term1",kappa + K_NA_spatial)
            # print("term2",kappa * NA + Sp_spatial)
            alpha = nx.exp(_psi(nx)(kappa + K_NA_spatial) - _psi(nx)(kappa * NA + Sp_spatial))
            alpha = alpha * kappa
            # print('here')
            # alpha = K_NA_spatial / NA
        else:
            # alpha = nx.exp(_psi(nx)(kappa + K_NA_spatial) - _psi(nx)(kappa * NA + Sp_spatial))
            alpha = nx.ones((NA), type_as=type_as) / NA
        # print("kappa: ",kappa)
        # print("alpha: ",alpha)

        # Update VnA
        if mode == "N":
            term1 = _dot(nx)(
                _pinv(nx)(sigma2 * lambdaVF * GammaSparse + _dot(nx)(U.T, nx.einsum("ij,i->ij", U, K_NA))),
                U.T,
            )
            SigmaDiag = sigma2 * nx.einsum("ij->i", nx.einsum("ij,ji->ij", U, term1))
            Coff = _dot(nx)(term1, (_dot(nx)(P, coordsB) - nx.einsum("ij,i->ij", RnA, K_NA)))
            VnA = _dot(nx)(
                U,
                Coff,
            )
        elif mode == "SN":
            if (sigma2 < 0.015 and s > 0.95) or (iter > 80):
                term1 = _dot(nx)(
                    _pinv(nx)(sigma2 * lambdaVF * GammaSparse + _dot(nx)(U.T, nx.einsum("ij,i->ij", U, K_NA))),
                    U.T,
                )
                SigmaDiag = sigma2 * nx.einsum("ij->i", nx.einsum("ij,ji->ij", U, term1))
                Coff = _dot(nx)(term1, (_dot(nx)(P, coordsB) - nx.einsum("ij,i->ij", RnA, K_NA)))
                VnA = _dot(nx)(
                    U,
                    Coff,
                )

        # Update R()
        if mode == "S" or mode == "SN":
            mu_XnA, mu_VnA, mu_XnB = (
                _dot(nx)(K_NA, coordsA) / Sp,
                _dot(nx)(K_NA, VnA) / Sp,
                _dot(nx)(K_NB, coordsB) / Sp,
            )
            XnABar, VnABar, XnBBar = coordsA - mu_XnA, VnA - mu_VnA, coordsB - mu_XnB
            A = -_dot(nx)(nx.einsum("ij,i->ij", VnABar, K_NA).T - _dot(nx)(P, XnBBar).T, XnABar)

            svdU, svdS, svdV = _linalg(nx).svd(A)
            C = _identity(nx, D, type_as)
            C[-1, -1] = _linalg(nx).det(_dot(nx)(svdU, svdV))
            R = _dot(nx)(_dot(nx)(svdU, C), svdV)
            s = (nx.einsum("ii", _dot(nx)(A, R.T)) + 10 / sigma2 + iter**2) / (
                nx.einsum("ii", _dot(nx)(nx.einsum("ij,i->ij", XnABar, K_NA).T, XnABar)) + 10 / sigma2 + iter**2
            )
            t = mu_XnB - mu_VnA - s * _dot(nx)(mu_XnA, R.T)
            RnA = s * _dot(nx)(coordsA, R.T) + t
        XAHat = RnA + VnA

        # Update sigma2 and beta2
        SpatialDistMat = cal_dist(XAHat, coordsB)
        sigma2_old = sigma2
        sigma2 = nx.maximum(
            (
                nx.einsum("ij,ij", spatial_P, SpatialDistMat) / (D * Sp_spatial)
                + nx.einsum("i,i", K_NA_spatial, SigmaDiag) / Sp_spatial
            ),
            _data(nx, 1e-3, type_as),
        )
        # if iter < 20:
        #     sigma2 = sigma2 * 100
        # beta2 = nx.maximum(
        #     nx.einsum("ij,ij", P, GeneDistMat) / (D * Sp)
        #     ,_data(nx,1e-3,type_as)
        # )
        sigma2_terc = nx.abs((sigma2 - sigma2_old) / sigma2)

    if verbose:
        lm.main_info(f"Key Parameters: gamma: {gamma}; beta2: {beta2}; sigma2: {sigma2}")

    if keep_size:
        area_after = _prod(nx)(nx.max(XAHat, axis=0) - nx.min(XAHat, axis=0))
        XAHat = XAHat * (area / area_after)

    if normalize_c:
        XAHat = XAHat * normalize_scale + normalize_mean_list[0]
        RnA = RnA * normalize_scale + normalize_mean_list[0]
        coarse_alignment = coarse_alignment * normalize_scale + normalize_mean_list[0]

    # Save aligned coordinates
    sampleA.obsm[key_added] = sampleA.obsm[spatial_key]
    # sampleA.obsm["Rigid_3d_align_spatial"] = sampleA.obsm[spatial_key]
    # sampleA.obsm["Coarse_alignment"] = sampleA.obsm[spatial_key]
    sampleB.obsm[key_added] = nx.to_numpy(XAHat).copy()
    sampleB.obsm["Rigid_3d_align_spatial"] = nx.to_numpy(RnA).copy()
    sampleB.obsm["Coarse_alignment"] = nx.to_numpy(coarse_alignment).copy()

    # save vector field
    if not (vecfld_key_added is None):
        sampleB.uns[vecfld_key_added] = {
            "s": nx.to_numpy(s),
            "R": nx.to_numpy(R),
            "t": nx.to_numpy(t),
            "beta": beta,
            "Coff": nx.to_numpy(Coff),
            "ctrl_pts": nx.to_numpy(ctrl_pts),
            "normalize_scale": nx.to_numpy(normalize_scale) if normalize_c else None,
            "normalize_mean_list": [nx.to_numpy(normalize_mean) for normalize_mean in normalize_mean_list]
            if normalize_c
            else None,
            "normalize_c": normalize_c,
            "dissimilarity": dissimilarity,
            "beta2": beta2,
            "sigma2": nx.to_numpy(sigma2),
            "gamma": nx.to_numpy(gamma),
            "NA": NA,
        }
    empty_cache(device=device)
    return (
        None if inplace else (sampleA, sampleB),
        nx.to_numpy(spatial_P.T),
        nx.to_numpy(sigma2),
    )


def get_shape_P(
    XnAHat: Union[np.ndarray, torch.Tensor],
    XnB: Union[np.ndarray, torch.Tensor],
    sigma2: Union[int, float, np.ndarray, torch.Tensor],
    alpha: Union[np.ndarray, torch.Tensor],
    gamma: Union[float, np.ndarray, torch.Tensor],
    SpatialDistMat: Union[np.ndarray, torch.Tensor],
) -> Union[np.ndarray, torch.Tensor]:
    assert XnAHat.shape[1] == XnB.shape[1], "XnAHat and XnB do not have the same number of features."
    assert XnAHat.shape[0] == alpha.shape[0], "XnAHat and alpha do not have the same length."
    nx = ot.backend.get_backend(XnAHat, XnB)
    NA, NB, D = XnAHat.shape[0], XnB.shape[0], XnAHat.shape[1]
    samples_s = nx.maximum(
        _prod(nx)(nx.max(XnAHat, axis=0) - nx.min(XnAHat, axis=0)),
        _prod(nx)(nx.max(XnB, axis=0) - nx.min(XnB, axis=0)),
    )
    outlier_s = samples_s * NA
    spatial_outlier = _power(nx)((2 * _pi(nx) * sigma2), _data(nx, D / 2, XnAHat)) * (1 - gamma) / (gamma * outlier_s)
    term1 = spatial_term1 = nx.einsum(
        "ij,i->ij",
        nx.exp(-SpatialDistMat / (2 * sigma2)),
        alpha,
    )
    term2 = spatial_outlier + nx.einsum("ij->j", term1)
    P = term1 / _unsqueeze(nx)(term2, 0)
    return P


def shape_align(
    points,
    mesh_points,
    R=None,
    max_iter: int = 100,
    dtype: str = "float64",
    device: str = "cpu",
    verbose: bool = True,
):

    (
        nx,
        type_as,
        coordsA,
        coordsB,
        normalize_scale_list,
        normalize_mean_list,
    ) = shape_align_preprocess(coordsA=points, coordsB=mesh_points, dtype=dtype, device=device, verbose=verbose)
    normalize_mean_list_points = normalize_mean_list[0]
    normalize_mean_list_mesh = normalize_mean_list[1]
    coordsA, coordsB = coordsA[0], coordsB[0]
    NA, NB, D = coordsA.shape[0], coordsB.shape[0], coordsA.shape[1]
    kappa = nx.ones((NA), type_as=type_as)
    alpha = nx.ones((NA), type_as=type_as)
    gamma, gamma_a, gamma_b = (
        _data(nx, 0.5, type_as),
        _data(nx, 1.0, type_as),
        _data(nx, 1.0, type_as),
    )
    minP, sigma2_terc, erc = (
        _data(nx, 1e-5, type_as),
        _data(nx, 1, type_as),
        _data(nx, 1e-4, type_as),
    )
    if R is None:
        R = np.eye(D)
    R = _data(nx, R, type_as)
    XAHat = coordsA
    XAHat = nx.dot(XAHat, R.T)
    VnA = nx.zeros(coordsA.shape, type_as=type_as)
    SpatialDistMat = cal_dist(XAHat, coordsB)
    sigma2 = 0.2 * nx.sum(SpatialDistMat) / (D * NA * NB)
    s = _data(nx, 1, type_as)
    iteration = (
        lm.progress_logger(range(max_iter), progress_name="Start morpho shape alignment")
        if verbose
        else range(max_iter)
    )
    coords_A_vis = []
    for iter in iteration:
        coords_A_vis.append(nx.to_numpy(XAHat * normalize_scale_list[1] + normalize_mean_list_mesh[0]))
        P = get_shape_P(
            XnAHat=XAHat,
            XnB=coordsB,
            sigma2=sigma2,
            alpha=alpha,
            gamma=gamma,
            SpatialDistMat=SpatialDistMat,
        )
        K_NA = nx.einsum("ij->i", P)
        K_NB = nx.einsum("ij->j", P)
        # Update gamma
        Sp = nx.einsum("ij->", P)
        gamma = nx.exp(_psi(nx)(gamma_a + Sp) - _psi(nx)(gamma_a + gamma_b + NB))
        # print('gamma:'+str(gamma))
        gamma = _data(nx, 0.99, type_as) if gamma > 0.99 else gamma
        gamma = _data(nx, 0.01, type_as) if gamma < 0.01 else gamma

        # Update alpha
        alpha = nx.exp(_psi(nx)(kappa + K_NA) - _psi(nx)(kappa * NA + Sp))

        # Update R()
        mu_XnA, mu_VnA, mu_XnB = (
            _dot(nx)(K_NA, coordsA) / Sp,
            _dot(nx)(K_NA, VnA) / Sp,
            _dot(nx)(K_NB, coordsB) / Sp,
        )
        XnABar, VnABar, XnBBar = coordsA - mu_XnA, VnA - mu_VnA, coordsB - mu_XnB
        A = -_dot(nx)(nx.einsum("ij,i->ij", VnABar, K_NA).T - _dot(nx)(P, XnBBar).T, XnABar)

        svdU, svdS, svdV = _linalg(nx).svd(A)
        C = _identity(nx, D, type_as)
        C[-1, -1] = _linalg(nx).det(_dot(nx)(svdU, svdV))
        R = _dot(nx)(_dot(nx)(svdU, C), svdV)
        s = (nx.einsum("ii", _dot(nx)(A, R.T))) / (
            nx.einsum("ii", _dot(nx)(nx.einsum("ij,i->ij", XnABar, K_NA).T, XnABar))
        )
        t = mu_XnB - mu_VnA - s * _dot(nx)(mu_XnA, R.T)
        XAHat = s * _dot(nx)(coordsA, R.T) + t

        # Update sigma2
        SpatialDistMat = cal_dist(XAHat, coordsB)
        sigma2_old = sigma2
        sigma2 = nx.maximum((nx.einsum("ij,ij", P, SpatialDistMat) / (D * Sp)), _data(nx, 1e-3, type_as))
        sigma2_terc = nx.abs((sigma2 - sigma2_old) / sigma2)
    if verbose:
        lm.main_info(f"Key Parameters: gamma: {gamma}; sigma2: {sigma2}")
    transformation_param = {
        "s": nx.to_numpy(s),
        "R": nx.to_numpy(R),
        "t": nx.to_numpy(t),
        "normalize_scale_list": [nx.to_numpy(normalize_scale) for normalize_scale in normalize_scale_list],
        "normalize_mean_list_points": [nx.to_numpy(normalize_mean) for normalize_mean in normalize_mean_list_points],
        "normalize_mean_list_mesh": [nx.to_numpy(normalize_mean) for normalize_mean in normalize_mean_list_mesh],
        "sigma2": nx.to_numpy(sigma2),
        "gamma": nx.to_numpy(gamma),
        "NA": NA,
    }
    empty_cache(device=device)
    return transformation_param, coords_A_vis


def get_global_P(
    XnAHat: Union[np.ndarray, torch.Tensor],
    XnB: Union[np.ndarray, torch.Tensor],
    sigma2: Union[int, float, np.ndarray, torch.Tensor],
    beta2: Union[int, float, np.ndarray, torch.Tensor],
    alpha: Union[np.ndarray, torch.Tensor],
    W: Union[np.ndarray, torch.Tensor],
    gamma: Union[float, np.ndarray, torch.Tensor],
    Sigma: Union[np.ndarray, torch.Tensor],
    GeneDistMat: Union[np.ndarray, torch.Tensor],
    SpatialDistMat: Union[np.ndarray, torch.Tensor],
    samples_s: Optional[List[float]] = None,
    outlier_variance: float = None,
) -> Union[np.ndarray, torch.Tensor]:
    """Calculating the generating probability matrix P.

    Args:
        XAHat: Current spatial coordinate of sample A. Shape: N x D.
        XnB : spatial coordinate of sample B (reference sample). Shape: M x D.
        sigma2: The spatial coordinate noise.
        beta2: The gene expression noise.
        alpha: A vector that encoding each probability generated by the spots of sample A. Shape: N x 1.
        gamma: Inlier proportion of sample A.
        Sigma: The posterior covariance matrix of Gaussian process. Shape: N x N or N x 1.
        GeneDistMat: The gene expression distance matrix between sample A and sample B. Shape: N x M.
        SpatialDistMat: The spatial coordinate distance matrix between sample A and sample B. Shape: N x M.
        samples_s: The space size of each sample. Area size for 2D samples and volume size for 3D samples.
        outlier_g: The outlier distribution output space volume attributed to gene expression.
    Returns:
        P: Generating probability matrix P. Shape: N x M.
    """

    assert XnAHat.shape[1] == XnB.shape[1], "XnAHat and XnB do not have the same number of features."
    assert XnAHat.shape[0] == alpha.shape[0], "XnAHat and alpha do not have the same length."
    assert XnB.shape[0] == W.shape[0], "XnB and W do not have the same length."
    assert XnAHat.shape[0] == Sigma.shape[0], "XnAHat and Sigma do not have the same length."

    nx = ot.backend.get_backend(XnAHat, XnB)
    NA, NB, D = XnAHat.shape[0], XnB.shape[0], XnAHat.shape[1]
    if samples_s is None:
        samples_s = nx.maximum(
            _prod(nx)(nx.max(XnAHat, axis=0) - nx.min(XnAHat, axis=0)),
            _prod(nx)(nx.max(XnB, axis=0) - nx.min(XnB, axis=0)),
        )
    outlier_s = samples_s * NA
    if outlier_variance is None:
        exp_SpatialMat = nx.exp(-SpatialDistMat / (2 * sigma2))
    else:
        exp_SpatialMat = nx.exp(-SpatialDistMat / (2 * sigma2 / outlier_variance))
    spatial_term1 = nx.einsum(
        "ij,j->ij",
        nx.einsum(
            "ij,i->ij",
            exp_SpatialMat,
            (_mul(nx)(alpha, nx.exp(-Sigma / sigma2))),
        ),
        W,
    )
    spatial_outlier = _power(nx)((2 * _pi(nx) * sigma2), _data(nx, D / 2, XnAHat)) * (1 - gamma) / (gamma * outlier_s)
    spatial_term2 = spatial_outlier + nx.einsum("ij->j", spatial_term1)
    spatial_P = spatial_term1 / _unsqueeze(nx)(spatial_term2, 0)
    spatial_inlier = 1 - spatial_outlier / (spatial_outlier + nx.einsum("ij->j", exp_SpatialMat))

    term1 = nx.einsum(
        "ij,j->ij",
        nx.einsum(
            "ij,i->ij",
            _mul(nx)(
                nx.exp(-SpatialDistMat / (2 * sigma2)),
                nx.exp(-GeneDistMat / (2 * beta2)),
            ),
            (_mul(nx)(alpha, nx.exp(-Sigma / sigma2))),
        ),
        W,
    )
    P = term1 / (_unsqueeze(nx)(nx.einsum("ij->j", term1), 0) + 1e-8)
    # P = nx.einsum("j,ij->ij",spatial_inlier,P)
    # term2 = _power(nx)((2 * _pi(nx) * sigma2), _data(nx, D / 2, XnAHat)) * _power(nx)(
    #     (2 * _pi(nx) * beta2), _data(nx, D / 2, XnAHat)
    # ) * (1 - gamma) / (gamma * outlier_s * outlier_g) + nx.einsum("ij->j", term1)
    # P = term1 / _unsqueeze(nx)(term2, 0)
    return P, spatial_P


def BA_align_multi(
    coords_model: Union[np.ndarray, torch.Tensor],
    genes_model: Union[np.ndarray, torch.Tensor],
    neighbor_coords: List[Union[np.ndarray, torch.Tensor]],
    neighbor_genes: List[Union[np.ndarray, torch.Tensor]],
    neighbor_weight: Optional[Union[list, torch.Tensor]] = None,
    nx: Union[ot.backend.TorchBackend, ot.backend.NumpyBackend] = ot.backend.NumpyBackend,
    type_as: Union[torch.Tensor, np.ndarray] = np.ndarray,
    iter_key_added: Optional[str] = "iter_spatial",
    key_added: str = "align_spatial",
    mode: Literal["S", "N", "SN"] = "SN",
    dissimilarity: str = "kl",
    max_iter: int = 100,
    lambdaVF: Union[int, float] = 1e2,
    beta: Union[int, float] = 0.01,
    beta2: Optional[Union[int, float]] = None,
    outlier_g: Union[int, float] = 1,
    K: Union[int, float] = 15,
    verbose: bool = True,
    init_Param=None,
    outlier_robust: bool = True,
    vis_optimiation: bool = False,
    file_name: Literal = "vis_optimization.gif",
):
    # convert data to nx type
    coords_model, genes_model = _data(nx, coords_model, type_as), _data(nx, genes_model, type_as)
    neighbor_coords = [_data(nx, neighbor_coord, type_as) for neighbor_coord in neighbor_coords]
    neighbor_genes = [_data(nx, neighbor_gene, type_as) for neighbor_gene in neighbor_genes]
    if type(neighbor_weight) is list:
        neighbor_weight = _data(nx, neighbor_weight, type_as)
    N_neighbor = len(neighbor_coords)
    N, D, G = coords_model.shape[0], coords_model.shape[1], genes_model.shape[1]
    neighbors_N = [neighbor.shape[0] for neighbor in neighbor_coords]
    neighbors_N_index = [np.sum(np.array(neighbors_N)[: i + 1]) for i in range(N_neighbor)]
    neighbors_N_index.insert(0, 0)
    neighbor_coords_compact = nx.concatenate(neighbor_coords, axis=0)
    neighbor_genes_cpmpact = nx.concatenate(neighbor_genes, axis=0)
    N_neighbor_sum = neighbor_coords_compact.shape[0]
    coords_model, neighbor_coords_compact = nx.from_numpy(coords_model, type_as=type_as), nx.from_numpy(
        neighbor_coords_compact, type_as=type_as
    )
    genes_model, neighbor_genes_cpmpact = nx.from_numpy(genes_model, type_as=type_as), nx.from_numpy(
        neighbor_genes_cpmpact, type_as=type_as
    )

    # Random select control points
    Unique_coordsA = _unique(nx, coords_model, 0)
    idx = random.sample(range(Unique_coordsA.shape[0]), min(K, Unique_coordsA.shape[0]))
    ctrl_pts = Unique_coordsA[idx, :]

    # construct the kernel
    GammaSparse = con_K(ctrl_pts, ctrl_pts, beta)
    U = con_K(coords_model, ctrl_pts, beta)

    # initialize parameters
    kappa = nx.ones((N), type_as=type_as)
    rho = N * neighbor_weight
    gamma_a, gamma_b = _data(nx, 1.0, type_as), _data(nx, 1.0, type_as)
    minP, sigma2_terc, erc = (
        _data(nx, 1e-5, type_as),
        _data(nx, 1, type_as),
        _data(nx, 1e-4, type_as),
    )

    if init_Param is not None:
        alpha = nx.from_numpy(init_Param["alpha"], type_as=type_as)
        P = nx.from_numpy(init_Param["P"], type_as=type_as)
        XnHat = nx.from_numpy(init_Param["XnHat"], type_as=type_as)
        Vn = nx.from_numpy(init_Param["Vn"], type_as=type_as)
        sigma2 = 2 * nx.from_numpy(init_Param["sigma2"], type_as=type_as)
        beta2 = nx.from_numpy(init_Param["beta2"], type_as=type_as)
        outlier_variance = nx.from_numpy(init_Param["outlier_variance"], type_as=type_as)
        gamma = nx.from_numpy(init_Param["gamma"], type_as=type_as)
        SigmaDiag = nx.from_numpy(init_Param["SigmaDiag"], type_as=type_as)
        Rn = nx.from_numpy(init_Param["Rn"], type_as=type_as)
        s = nx.from_numpy(init_Param["s"], type_as=type_as)
        R = nx.from_numpy(init_Param["R"], type_as=type_as)
        t = nx.from_numpy(init_Param["t"], type_as=type_as)
        W = nx.from_numpy(init_Param["W"], type_as=type_as)
        SpatialDistMat = nx.from_numpy(init_Param["SpatialDistMat"], type_as=type_as)
        GeneDistMat = nx.from_numpy(init_Param["GeneDistMat"], type_as=type_as)
    else:

        alpha = nx.ones((N), type_as=type_as)
        Vn = nx.zeros(coords_model.shape, type_as=type_as)
        SpatialDistMat = cal_dist(coords_model, neighbor_coords_compact)
        sigma2 = 100 * nx.sum(SpatialDistMat) / (D * N * N_neighbor_sum)
        GeneDistMat = calc_exp_dissimilarity(X_A=genes_model, X_B=neighbor_genes_cpmpact, dissimilarity=dissimilarity)
        minGeneDistMat = nx.maximum(nx.min(GeneDistMat, 1), _data(nx, 0.05, type_as))
        if beta2 is None:
            # beta2 = minGeneDistMat[nx.argsort(minGeneDistMat)[int(GeneDistMat.shape[0]*0.1)]] / 5
            beta2 = minGeneDistMat[nx.argsort(minGeneDistMat)[int(GeneDistMat.shape[0] * 0.1)]] / 2
        beta2_end = _data(nx, beta2, type_as)
        beta2_init = minGeneDistMat[nx.argsort(minGeneDistMat)[int(GeneDistMat.shape[0] * 0.05)]] / 10
        beta2_decrease = _power(nx)(beta2_end / beta2_init, max_iter / 2)
        GeneDistMatMinus = GeneDistMat - nx.min(GeneDistMat, axis=1, keepdims=True)
        # GeneDistMat = GeneDistMat - nx.min(GeneDistMat, axis=1, keepdims=True)
        # GeneDistMat = nx.exp(-GeneDistMat / (2 * beta2))
        gamma = _data(nx, 0.5, type_as)
        SigmaDiag = nx.zeros((N), type_as=type_as)
        XnHat, Rn = coords_model, coords_model

        outlier_variance = 1
        s = _data(nx, 1, type_as)
        W = nx.concatenate(
            [neighbor_weight[i] * nx.ones((neighbor_N), type_as=type_as) for i, neighbor_N in enumerate(neighbors_N)]
        )

    outlier_variance_decrease = _power(nx)(_data(nx, 20, type_as), 1 / (max_iter))

    if iter_key_added is not None:
        iter_key_added_data = dict()
        iter_key_added_data[key_added] = {}
        iter_key_added_data["sigma2"] = {}
        iter_key_added_data["scale"] = {}

    if vis_optimiation:
        import matplotlib.animation as animation
        import matplotlib.pyplot as plt

        plt.ioff()
        fig, ax = plt.subplots(figsize=(10, 5))
        ax.axis("equal")
        XnHat_list = []
        s_list = []
        sigma2_list = []
        ax.set_xlim(
            (
                1.3 * torch.min(neighbor_coords_compact[:, 0]).cpu().numpy(),
                1.3 * torch.max(neighbor_coords_compact[:, 0]).cpu().numpy(),
            )
        )
        ax.set_ylim(
            (
                1.3 * torch.min(neighbor_coords_compact[:, 1]).cpu().numpy(),
                1.3 * torch.max(neighbor_coords_compact[:, 1]).cpu().numpy(),
            )
        )
        ax.set_xticks([])
        ax.set_yticks([])

    iteration = (
        lm.progress_logger(range(max_iter), progress_name="Start morpho alignment") if verbose else range(max_iter)
    )
    for iter in iteration:
        if sigma2_terc < erc and sigma2 < 0.001:
            break

        if vis_optimiation:
            XnHat_list.append(XnHat)
            sigma2_list.append(sigma2)
            s_list.append(s)

        if (init_Param is None) and (iter < 20):
            P, spatial_P = get_global_P(
                XnAHat=XnHat,
                XnB=neighbor_coords_compact,
                sigma2=sigma2,
                beta2=beta2_init,
                alpha=alpha,
                W=W,
                gamma=gamma,
                Sigma=SigmaDiag,
                GeneDistMat=GeneDistMatMinus,
                SpatialDistMat=SpatialDistMat,
            )
        else:
            if init_Param is None:
                beta2 = nx.minimum(beta2 * beta2_decrease, beta2_end)
            P, spatial_P = get_global_P(
                XnAHat=XnHat,
                XnB=neighbor_coords_compact,
                sigma2=sigma2,
                beta2=beta2,
                alpha=alpha,
                W=W,
                gamma=gamma,
                Sigma=SigmaDiag,
                GeneDistMat=GeneDistMat,
                SpatialDistMat=SpatialDistMat,
                outlier_variance=outlier_variance,
            )
            if outlier_robust and (init_Param is None):
                outlier_variance = outlier_variance * outlier_variance_decrease
        K_NA = nx.einsum("ij->i", P)
        K_NB = nx.einsum("ij->j", P)
        K_NA_spatial = nx.einsum("ij->i", spatial_P)
        K_NB_spatial = nx.einsum("ij->j", spatial_P)
        # Update gamma
        Sp = nx.einsum("ij->", P)
        Sp_spatial = nx.einsum("ij->", spatial_P)
        gamma = nx.exp(_psi(nx)(gamma_a + Sp_spatial) - _psi(nx)(gamma_a + gamma_b + N_neighbor_sum))
        gamma = _data(nx, 0.99, type_as) if gamma > 0.99 else gamma
        gamma = _data(nx, 0.01, type_as) if gamma < 0.01 else gamma

        # Update W
        K_NB_part = [K_NB_spatial[neighbors_N_index[i] : neighbors_N_index[i + 1]] for i in range(N_neighbor)]
        Sp_part = _data(
            nx,
            [nx.sum(K_NB_spatial[neighbors_N_index[i] : neighbors_N_index[i + 1]]) for i in range(N_neighbor)],
            type_as,
        )
        W = nx.exp(_psi(nx)(rho + Sp_part) - _psi(nx)(rho * N_neighbor + Sp_spatial))
        W = nx.concatenate([W[i] * nx.ones((neighbor_N), type_as=type_as) for i, neighbor_N in enumerate(neighbors_N)])

        # Update alpha
        alpha = nx.exp(_psi(nx)(kappa + K_NA_spatial) - _psi(nx)(kappa * N + Sp_spatial))

        # Update VnA
        if mode == "N":
            term1 = _dot(nx)(
                _pinv(nx)(sigma2 * lambdaVF * GammaSparse + _dot(nx)(U.T, nx.einsum("ij,i->ij", U, K_NA))),
                U.T,
            )
            SigmaDiag = sigma2 * nx.einsum("ij->i", nx.einsum("ij,ji->ij", U, term1))
            VnA = _dot(nx)(
                U,
                _dot(nx)(
                    term1,
                    (_dot(P, neighbor_coords_compact) - nx.einsum("ij,i->ij", coords_model, K_NA)),
                ),
            )
        elif mode == "SN":
            if sigma2 < 0.015 and s > 0.95:
                term1 = _dot(nx)(
                    _pinv(nx)(sigma2 * lambdaVF * GammaSparse + _dot(nx)(U.T, nx.einsum("ij,i->ij", U, K_NA))),
                    U.T,
                )
                SigmaDiag = sigma2 * nx.einsum("ij->i", nx.einsum("ij,ji->ij", U, term1))
                Vn = _dot(nx)(
                    U,
                    _dot(nx)(
                        term1,
                        (_dot(nx)(P, neighbor_coords_compact) - nx.einsum("ij,i->ij", Rn, K_NA)),
                    ),
                )

        # Update R()
        if mode == "S" or mode == "SN":
            mu_XnA, mu_VnA, mu_XnB = (
                _dot(nx)(K_NA, coords_model) / Sp,
                _dot(nx)(K_NA, Vn) / Sp,
                _dot(nx)(K_NB, neighbor_coords_compact) / Sp,
            )
            XnABar, VnABar, XnBBar = (
                coords_model - mu_XnA,
                Vn - mu_VnA,
                neighbor_coords_compact - mu_XnB,
            )
            A = -_dot(nx)(nx.einsum("ij,i->ij", VnABar, K_NA).T - _dot(nx)(P, XnBBar).T, XnABar)
            svdU, svdS, svdV = _linalg(nx).svd(A)
            C = _identity(nx, D, type_as)
            C[-1, -1] = _linalg(nx).det(_dot(nx)(svdU, svdV))
            R = _dot(nx)(_dot(nx)(svdU, C), svdV)
            s = (nx.einsum("ii", _dot(nx)(A, R.T)) + 10 / sigma2 + iter**2) / (
                nx.einsum("ii", _dot(nx)(nx.einsum("ij,i->ij", XnABar, K_NA).T, XnABar)) + 10 / sigma2 + iter**2
            )
            t = mu_XnB - mu_VnA - s * _dot(nx)(mu_XnA, R.T)
            Rn = s * _dot(nx)(coords_model, R.T) + t

        XnHat = Rn + Vn

        # Update sigma2 and beta2
        SpatialDistMat = cal_dist(XnHat, neighbor_coords_compact)
        sigma2_old = sigma2
        if init_Param is None:
            sigma2 = nx.maximum(_data(nx, 30 / (iter + 1), type_as), _data(nx, 1, type_as)) * (
                nx.einsum("ij,ij", P, SpatialDistMat) / (D * Sp) + nx.einsum("i,i", K_NA, SigmaDiag) / Sp
            )
        else:
            sigma2 = nx.einsum("ij,ij", P, SpatialDistMat) / (D * Sp) + nx.einsum("i,i", K_NA, SigmaDiag) / Sp
        sigma2_terc = nx.abs((sigma2 - sigma2_old) / sigma2)

    if vis_optimiation:
        slice_colors = [
            "#E41A1C",
            "#B45F00",
            "#707E00",
            "#008D01",
            "#009466",
            "#0095B2",
        ]
        artists = []
        for i in range(iter - 1):
            frame = []
            for j in range(N_neighbor):
                frame_j = ax.scatter(
                    neighbor_coords[j][:, 0].cpu().numpy(),
                    neighbor_coords[j][:, 1].cpu().numpy(),
                    marker="o",
                    s=5,
                    c=slice_colors[1 + j % (len(slice_colors) - 1)],
                )
                frame.append(frame_j)
            frame1 = ax.scatter(
                XnHat_list[i][:, 0].cpu().numpy(),
                XnHat_list[i][:, 1].cpu().numpy(),
                marker="o",
                s=5,
                c=slice_colors[0],
            )
            frame.append(frame1)
            # frame2 = ax.scatter(coordsB[:,0],coordsB[:,1],marker='o',s=5,c='r')
            title_text = "Iter: {}, sigma2: {:.3f}, s: {:.3f}.".format(
                i, sigma2_list[i].cpu().numpy(), s_list[i].cpu().numpy()
            )
            tit = ax.text(
                (
                    np.min(neighbor_coords_compact[:, 0].cpu().numpy())
                    + np.max(neighbor_coords_compact[:, 0].cpu().numpy())
                )
                / 2,
                1.2 * np.max(neighbor_coords_compact[:, 1].cpu().numpy()),
                title_text,
                ha="center",
                va="bottom",
                size=16,
                weight="bold",
            )
            frame.append(tit)
            artists.append(frame)
        ani = animation.ArtistAnimation(fig=fig, artists=artists, interval=4, blit=False)
        ani.save(file_name, fps=10)
        plt.close()

    if verbose:
        lm.main_info(f"Key Parameters: gamma: {gamma}; beta2: {beta2}; sigma2: {sigma2}")

    param = dict()
    param["XnHat"] = nx.to_numpy(XnHat)
    param["P"] = nx.to_numpy(P.T)
    param["R"] = nx.to_numpy(R)
    param["t"] = nx.to_numpy(t)
    param["alpha"] = nx.to_numpy(alpha)
    param["Vn"] = nx.to_numpy(Vn)
    param["sigma2"] = nx.to_numpy(sigma2)
    param["beta2"] = nx.to_numpy(beta2)
    param["outlier_variance"] = nx.to_numpy(outlier_variance)
    param["gamma"] = nx.to_numpy(gamma)
    param["SigmaDiag"] = nx.to_numpy(SigmaDiag)
    param["Rn"] = nx.to_numpy(Rn)
    param["s"] = nx.to_numpy(s)
    param["W"] = nx.to_numpy(W)
    param["SpatialDistMat"] = nx.to_numpy(SpatialDistMat)
    param["GeneDistMat"] = nx.to_numpy(GeneDistMat)
    return param
